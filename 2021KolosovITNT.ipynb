{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/v101/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#import annoy\n",
    "\n",
    "import numpy as np\n",
    "import gensim, zipfile\n",
    "\n",
    "from scipy.stats import spearmanr, kendalltau, rankdata\n",
    "from scipy.spatial.distance import cosine, euclidean, norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprop(filename, model):\n",
    "\n",
    "    with zipfile.ZipFile(model, 'r') as archive:\n",
    "        stream = archive.open('model.bin')\n",
    "        m = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)\n",
    "    print(len(m.index_to_key))\n",
    "    \n",
    "    triplets=[]\n",
    "    with open(filename, 'r') as f:\n",
    "        ff=f.readlines()\n",
    "        for i in ff[1:]:\n",
    "            fff=i.split(',')\n",
    "            if fff[0] in m and fff[1] in m and fff[0] != fff[1]: #tiger, tiger(frozenset for one element is bad)\n",
    "                        triplets.append([fff[0], fff[1], fff[4][:-1]])\n",
    "            else:\n",
    "                pass\n",
    "    print(len(triplets))\n",
    "    \n",
    "    return triplets, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(g, m, y_pred_iv, sim_func):\n",
    "    \n",
    "    gold_pairs=[]\n",
    "    w2v_pairs=[]\n",
    "    ivis_pairs=[]\n",
    "\n",
    "    for i,j in g.dict.keys():\n",
    "        gold_pairs.append(g.sim(i, j))\n",
    "        w2v_pairs.append(sim_func(m[i], m[j]))#m.distance(i, j))\n",
    "\n",
    "        dI = y_pred_iv[list(g.vocab).index(i)]\n",
    "        dII = y_pred_iv[list(g.vocab).index(j)]\n",
    "        result = sim_func(dI, dII)#1-\n",
    "        ivis_pairs.append(result)\n",
    "\n",
    "    results=(spearmanr(gold_pairs, w2v_pairs), \n",
    "             spearmanr(gold_pairs, ivis_pairs), \n",
    "             kendalltau(gold_pairs, w2v_pairs), \n",
    "             kendalltau(gold_pairs, ivis_pairs))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gold():\n",
    "    \n",
    "    def __init__(self, triplets):\n",
    "        self.dict={frozenset([i[0], i[1]]): float(i[2]) for i in triplets} #problem if i[0]==i[1], bypassed in preprop\n",
    "        self.vocab=np.array(list(set.union(set(list(zip(*triplets))[0]), set(list(zip(*triplets))[1])))) #nice hack:)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.vocab[index]\n",
    "    \n",
    "    def sim(self, first_word, second_word):\n",
    "        return self.dict[frozenset((first_word, second_word))]\n",
    "        \n",
    "    def sim_matrix(self, k):\n",
    "        res=np.zeros((len(self.vocab), k), dtype=\"int64\")\n",
    "        for ind_i, obj_i in enumerate(self.vocab):\n",
    "            cur_res=[]\n",
    "            for ind_j, obj_j in enumerate(self.vocab):\n",
    "                try:\n",
    "                    cur_res.append(self.sim(obj_i, obj_j))\n",
    "                except:\n",
    "                    pass\n",
    "            cur_res=sorted(cur_res, reverse=True) #по убыванию\n",
    "            if len(cur_res) < k:\n",
    "                cur_res=cur_res+[-1]*(k-len(cur_res))\n",
    "            res[ind_i,:]=cur_res[:k]\n",
    "        return res\n",
    "    \n",
    "    def nei_matrix(self, k):\n",
    "        res=np.zeros((len(self.vocab), k), dtype=\"int64\")\n",
    "        for ind_i, obj_i in enumerate(self.vocab):\n",
    "            cur_res=[]\n",
    "            for ind_j, obj_j in enumerate(self.vocab):\n",
    "                try:\n",
    "                    cur_res.append((self.sim(obj_i, obj_j), ind_j))\n",
    "                except:\n",
    "                    pass\n",
    "            cur_res.sort(key=lambda x:x[0], reverse=True) #по убыванию\n",
    "            cur_list=list(zip(*cur_res))[1]\n",
    "            if len(cur_list) < k:\n",
    "                cur_list=list(cur_list)+[ind_i]*(k-len(cur_list))\n",
    "            res[ind_i,:]=cur_list[:k]\n",
    "        return res\n",
    "    \n",
    "    def nei_list(self):\n",
    "        res=[]\n",
    "        for ind_i, obj_i in enumerate(self.vocab):\n",
    "            cur_res=[]\n",
    "            for ind_j, obj_j in enumerate(self.vocab):\n",
    "                try:\n",
    "                    cur_res.append((self.sim(obj_i, obj_j), ind_j))\n",
    "                except:\n",
    "                    pass\n",
    "            cur_res.sort(key=lambda x:x[0], reverse=True) #по убыванию\n",
    "            cur_list=list(zip(*cur_res))[1]\n",
    "            #res[ind_i,:]=cur_list\n",
    "            res.append(cur_list)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ivis based part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from abc import ABC#, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TripletGenerator(Sequence, ABC):\n",
    "    def __init__(self, X, neighbour_matrix, batch_size=32):\n",
    "        print(batch_size, X)\n",
    "        if batch_size > X.shape[0]:\n",
    "            raise Exception('''batch_size value larger than num_rows in dataset\n",
    "                            (batch_size={}, rows={}). Lower batch_size to a\n",
    "                            smaller value.'''.format(batch_size, X.shape[0]))\n",
    "        self.X = X\n",
    "        self.neighbour_matrix = neighbour_matrix\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = range(idx * self.batch_size,\n",
    "                              min((idx + 1) * self.batch_size, self.X.shape[0]))\n",
    "\n",
    "        label_batch = self.get_labels(batch_indices)\n",
    "        triplet_batch = [self.get_triplet(row_index)\n",
    "                         for row_index in batch_indices]\n",
    "\n",
    "        if issparse(self.X):\n",
    "            triplet_batch = [[e.toarray()[0] for e in t] for t in triplet_batch]\n",
    "\n",
    "        triplet_batch = np.array(triplet_batch)\n",
    "\n",
    "        return self.output_triplets(triplet_batch, label_batch)\n",
    "\n",
    "    def get_triplet(self, idx):\n",
    "        triplet = []\n",
    "        neighbour_list = self.get_neighbours(idx)\n",
    "        neighbour_list = np.array(neighbour_list, dtype=np.uint32)\n",
    "        #print(neighbour_list)\n",
    "\n",
    "        if len(neighbour_list) > 1:\n",
    "            # Take a random neighbour as positive\n",
    "            positive_ind = np.random.randint(0, len(neighbour_list)-1)\n",
    "\n",
    "            # Take a random non-neighbour as negative\n",
    "            # Pick a random index until one fits constraint, usually faster.\n",
    "            negative_ind = np.random.randint(positive_ind+1, len(neighbour_list))\n",
    "        else:\n",
    "            positive_ind=0\n",
    "            negative_ind=0\n",
    "\n",
    "        positive_ind=neighbour_list[positive_ind]\n",
    "        negative_ind=neighbour_list[negative_ind]\n",
    "\n",
    "        triplet = [self.X[idx], self.X[positive_ind], self.X[negative_ind]] #add #changed\n",
    "        return triplet\n",
    "\n",
    "    def get_neighbours(self, idx):\n",
    "        return self.neighbour_matrix[idx]\n",
    "    '''\n",
    "    @abstractmethod\n",
    "    def get_labels(self, batch_indices):\n",
    "        raise NotImplementedError(\"Override this method with a concrete implementation\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def output_triplets(self, triplet_batch, label_batch):\n",
    "        raise NotImplementedError(\"Override this method with a concrete implementation\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedTripletGenerator(TripletGenerator):\n",
    "    def __init__(self, X, neighbour_matrix, batch_size=32):\n",
    "        super().__init__(X, neighbour_matrix, batch_size)\n",
    "        self.placeholder_labels = np.empty(batch_size, dtype=np.uint8)\n",
    "\n",
    "    def get_labels(self, batch_indices):\n",
    "        return self.placeholder_labels[:len(batch_indices)]\n",
    "\n",
    "    def output_triplets(self, triplet_batch, label_batch):\n",
    "        return tuple([triplet_batch[:, 0], triplet_batch[:, 1], triplet_batch[:, 2]]), label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_from_neighbour_matrix(X, Y, neighbour_matrix, batch_size):\n",
    "     return UnsupervisedTripletGenerator(X, neighbour_matrix, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_loss(loss_fn=None, *, name=None):\n",
    "    \"\"\"Registers a class definition or Callable as an ivis loss function.\n",
    "    A mapping will be created between the name and the loss function passed.\n",
    "    If a class definition is provided, an instance will be created, passing the name\n",
    "    as an argument.\n",
    "\n",
    "    If no name is provided to this function, the name of the passed function will be used\n",
    "    as a key.\n",
    "\n",
    "    The loss function must have two parameters, (y_true, y_pred)\n",
    "    and calculates the loss for a batch of triplet inputs (y_pred).\n",
    "    y_pred is expected to be of shape: (3, batch_size, embedding_dims).\n",
    "\n",
    "    Usage:\n",
    "        .. code-block:: python\n",
    "\n",
    "            @register_loss\n",
    "            def custom_loss(y_true, y_pred):\n",
    "                pass\n",
    "            model = Ivis(distance='custom_loss')\"\"\"\n",
    "\n",
    "    if loss_fn is None:\n",
    "        return functools.partial(register_loss, name=name)\n",
    "\n",
    "    key = name or loss_fn.__name__\n",
    "    if isinstance(loss_fn, type):\n",
    "        loss_dict[key] = loss_fn(name=key)\n",
    "    else:\n",
    "        loss_dict[key] = loss_fn\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(distance='pn'):\n",
    "    \"\"\"Returns a previously registered triplet loss function associated\n",
    "    with the string 'distance'. If passed a callable, just returns it.\"\"\"\n",
    "    if callable(distance):\n",
    "        return distance\n",
    "    try:\n",
    "        loss_fn = loss_dict[distance]\n",
    "        return loss_fn\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Loss function {} not registered with ivis\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_loss(name='euclidean')\n",
    "class EuclideanTripletLoss:\n",
    "    \"\"\"Calculates the standard triplet loss between anchor, positive and negative\n",
    "    examples in a triplet based on euclidean distance.\"\"\"\n",
    "    def __init__(self, margin=0, name=None):\n",
    "        self.margin = margin\n",
    "        name = name or self.__class__.__name__\n",
    "        self.__name__ = name\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        anchor, positive, negative = tf.unstack(y_pred)\n",
    "        return K.mean(K.maximum(euclidean_distance(anchor, positive) - euclidean_distance(anchor, negative) + self.margin, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_loss(name='cosine')\n",
    "class CosineTripletLoss:\n",
    "    \"\"\"Calculates the standard triplet loss between anchor, positive and negative\n",
    "    examples in a triplet based on cosine distance.\"\"\"\n",
    "    def __init__(self, margin=0, name=None):\n",
    "        self.margin = margin\n",
    "        name = name or self.__class__.__name__\n",
    "        self.__name__ = name\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        anchor, positive, negative = tf.unstack(y_pred)\n",
    "        return K.mean(K.maximum(cosine_distance(anchor, positive) - cosine_distance(anchor, negative) + self.margin, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_network(base_network, embedding_dims=2, embedding_l2=0.0):\n",
    "    \"\"\" Creates a triplet Siamese Neural Network from a base_network.\n",
    "    The base network will have an extra Dense layer of the requested embedding_dims added to\n",
    "    the end if embedding_dims is not None.\n",
    "\n",
    "    The outputs of the three network heads will be stacked into the shape:\n",
    "    (3, batch_size, embedding_dims) unless embedding_dims is None (in which case the existing dims\n",
    "    of last base_network layer will be used).\n",
    "\n",
    "    Outputs: tuple(\n",
    "        model: tf.keras.models.Model. The constructed triplet Siamese network\n",
    "        processed_a: tf.keras.layers.Dense. Result of applying the base_network to anchor input.\n",
    "        processed_p: tf.keras.layers.Dense. Result of applying the base_network to positive input.\n",
    "        processed_n: tf.keras.layers.Dense. Result of applying the base_network to negative input.\n",
    "    ) \"\"\"\n",
    "\n",
    "    def output_shape(shapes):\n",
    "        shape1, _, _ = shapes\n",
    "        return (3, shape1[0],)\n",
    "   \n",
    "    input_a = Input(shape=base_network.input_shape[1:])\n",
    "    input_p = Input(shape=base_network.input_shape[1:])\n",
    "    input_n = Input(shape=base_network.input_shape[1:])\n",
    "    '''\n",
    "    if embedding_dims is None:\n",
    "        embeddings = base_network.output\n",
    "    else:\n",
    "        embeddings = Dense(embedding_dims,\n",
    "                           kernel_regularizer=l2(embedding_l2))(base_network.output)\n",
    "    '''\n",
    "    embeddings = base_network.output\n",
    "    network = Model(base_network.input, embeddings)\n",
    "\n",
    "    processed_a = network(input_a)\n",
    "    processed_p = network(input_p)\n",
    "    processed_n = network(input_n)\n",
    "\n",
    "    triplet = Lambda(K.stack,\n",
    "                     output_shape=output_shape,\n",
    "                     name='stacked_triplets')([processed_a,\n",
    "                                               processed_p,\n",
    "                                               processed_n],)\n",
    "    model = Model([input_a, input_p, input_n], triplet)\n",
    "\n",
    "    return model, processed_a, processed_p, processed_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=-1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - tf.math.reduce_sum(tf.nn.l2_normalize(x, axis=1) * tf.nn.l2_normalize(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasSequence(tf.keras.utils.Sequence):\n",
    "    \"\"\"Wraps inputs into a Keras Sequence to allow Keras models to predict on\n",
    "    arbitrary inputs which may be out of memory.\"\"\"\n",
    "    def __init__(self, X, batch_size=32):\n",
    "        self.X = X\n",
    "        self.batch_size = batch_size\n",
    "        self.placeholder_labels = np.empty(batch_size, dtype=np.uint8)\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.X.shape[0] / float(self.batch_size)))\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = range(index * self.batch_size, min((index + 1) * self.batch_size, self.X.shape[0]))\n",
    "        batch = np.array([self.X[i] for i in batch_indices])\n",
    "        placeholder_labels = self.placeholder_labels[:len(batch_indices)]\n",
    "        return batch, placeholder_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corrector(BaseEstimator):\n",
    "\n",
    "    def __init__(self, \n",
    "                 embedding_dims=2, \n",
    "                 k=150, \n",
    "                 distance='pn', \n",
    "                 batch_size=128,\n",
    "                 epochs=1000, \n",
    "                 n_epochs_without_progress=20, \n",
    "                 model=None,\n",
    "                 neighbour_matrix=None, \n",
    "                 verbose=1):\n",
    "\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.n_epochs_without_progress = n_epochs_without_progress\n",
    "        \n",
    "        self.model = model\n",
    "        self.model_ = None\n",
    "                \n",
    "        self.neighbour_matrix = neighbour_matrix\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.encoder = None\n",
    "        self.loss_history_ = []\n",
    "        self.callbacks = []\n",
    "\n",
    "    def _fit(self, X, Y=None, shuffle_mode=True):\n",
    "\n",
    "        datagen = generator_from_neighbour_matrix(X, Y,\n",
    "                                                  neighbour_matrix=self.neighbour_matrix,\n",
    "                                                  batch_size=self.batch_size)\n",
    "\n",
    "        loss_monitor = 'loss'\n",
    "        try:\n",
    "            triplet_loss_func = triplet_loss(distance=self.distance)\n",
    "        except KeyError:\n",
    "            raise ValueError('Loss function `{}` not implemented.'.format(self.distance))\n",
    "\n",
    "        self.model_, anchor_embedding, _, _ = \\\n",
    "            triplet_network(self.model,\n",
    "                            embedding_dims=self.embedding_dims)\n",
    "\n",
    "        self.model_.compile(optimizer='adam', loss=triplet_loss_func)\n",
    "            \n",
    "        self.encoder = self.model_.layers[3]\n",
    "\n",
    "        if self.verbose > 0:\n",
    "            print('Training neural network')\n",
    "\n",
    "        hist = self.model_.fit(\n",
    "            datagen,\n",
    "            epochs=self.epochs,\n",
    "            callbacks=self.callbacks + [EarlyStopping(monitor=loss_monitor,\n",
    "                                                      patience=self.n_epochs_without_progress)],\n",
    "            shuffle=shuffle_mode,\n",
    "            steps_per_epoch=int(np.ceil(X.shape[0] / self.batch_size)),\n",
    "            verbose=self.verbose)\n",
    "        self.loss_history_ += hist.history['loss']\n",
    "\n",
    "    '''\n",
    "    def fit(self, X, Y=None, shuffle_mode=True):\n",
    "        self._fit(X, Y, shuffle_mode)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, Y=None, shuffle_mode=True):\n",
    "        self.fit(X, Y, shuffle_mode)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        embedding = self.encoder.predict(KerasSequence(X, batch_size=self.batch_size),\n",
    "                                         verbose=self.verbose)\n",
    "        return embedding\n",
    "    '''\n",
    " \n",
    "    def fit_transform(self, X, Y=None, shuffle_mode=True):\n",
    "        self._fit(X, Y, shuffle_mode)\n",
    "        embedding = self.encoder.predict(KerasSequence(X, batch_size=self.batch_size),\n",
    "                                         verbose=self.verbose)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, AlphaDropout, Lambda, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_experiment(lemm, expert, func):\n",
    "    \n",
    "    inputs = Input(shape=300)\n",
    "    q = Dense(300,# activation=None,\n",
    "              kernel_initializer='lecun_normal')(inputs)\n",
    "    p=Model(inputs, q)\n",
    "    \n",
    "    model='../'+lemm\n",
    "    dataset='../'+expert\n",
    "    t, m = preprop(dataset, model)\n",
    "    g=Gold(t)\n",
    "    x = m[g.vocab]\n",
    "    \n",
    "    iv = Corrector(\n",
    "            embedding_dims=300, \n",
    "            distance=func, \n",
    "            batch_size = 200,\n",
    "            epochs=100, \n",
    "            neighbour_matrix=g.nei_list(), \n",
    "            model=p)#, margin=0)\n",
    "    \n",
    "    y_pred_iv = iv.fit_transform(x)\n",
    "    \n",
    "    print(\"aaa\")\n",
    "    if func == 'euclidean':\n",
    "        return validate(g, m, y_pred_iv, euclidean)\n",
    "    elif func == 'cosine':\n",
    "        return validate(g, m, y_pred_iv, cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. lemmatize wordsim euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273992\n",
      "349\n",
      "200 [[ 0.041929  0.063848  0.003732 ...  0.142079 -0.027583  0.069721]\n",
      " [ 0.082989 -0.022708  0.104097 ...  0.046328 -0.084275  0.020042]\n",
      " [ 0.069058 -0.006184 -0.089413 ... -0.082803 -0.013278  0.022188]\n",
      " ...\n",
      " [-0.051873 -0.052932  0.086663 ...  0.011292  0.003633 -0.019811]\n",
      " [ 0.053438  0.051815  0.001467 ... -0.048915  0.069824 -0.068646]\n",
      " [ 0.119095  0.09691   0.044006 ...  0.045905 -0.042312 -0.002537]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0079\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0039\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0040\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0013\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6.0117e-04\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0024\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.8783e-04\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.7374e-05\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.3345e-05\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6420e-04\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.5458e-04\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.6754e-04\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.0415e-04\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9.8198e-05\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.4853e-04\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.0493e-04\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.7376e-04\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.5073e-04\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0031\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.9606e-04\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.9523e-04\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.1986e-04\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.2417e-07\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.9683e-04\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 9.7136e-05\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.1790e-04\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.2623e-04\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.0979e-05\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.5886e-04\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.8057e-05\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.2949e-04\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.4613e-05\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3843e-04\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.2676e-05\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.1892e-04\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.8271e-04\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.2514e-05\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.0015e-06\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.5184e-04\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.5535e-04\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.3381e-04\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9683e-05\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.9644e-04\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 2.4206e-05\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.6717e-06\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.7055e-04\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.6373e-05\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2001e-05\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.7223e-04\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.9975e-05\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7084941993379477, pvalue=1.797352350373244e-54),\n",
       " SpearmanrResult(correlation=-0.7551552839322319, pvalue=1.2995209699129477e-65),\n",
       " KendalltauResult(correlation=-0.5129792004348761, pvalue=2.8047085167872706e-46),\n",
       " KendalltauResult(correlation=-0.560144394070951, pvalue=7.760110477155038e-55))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('5.zip', 'WordSim-353-standartized.csv', 'euclidean')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7084941993379477, pvalue=1.797352350373244e-54),\n",
       " SpearmanrResult(correlation=-0.7551552839322319, pvalue=1.2995209699129477e-65),\n",
       " KendalltauResult(correlation=-0.5129792004348761, pvalue=2.8047085167872706e-46),\n",
       " KendalltauResult(correlation=-0.560144394070951, pvalue=7.760110477155038e-55))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. lemmatize wordsim cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273992\n",
      "349\n",
      "200 [[ 0.113458 -0.062431  0.060432 ...  0.007231 -0.013264  0.024604]\n",
      " [-0.018223 -0.062071 -0.054039 ... -0.039914  0.055739 -0.067869]\n",
      " [ 0.032351 -0.025752  0.024376 ...  0.031781 -0.002401 -0.024485]\n",
      " ...\n",
      " [ 0.014075 -0.035853  0.069998 ... -0.014092 -0.032933 -0.051645]\n",
      " [ 0.110389  0.050713 -0.005143 ... -0.046878  0.013409 -0.004632]\n",
      " [ 0.046215  0.093834  0.078839 ... -0.011977 -0.044008 -0.076616]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 8ms/step - loss: 0.0174\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7085277934443607, pvalue=1.7677073163502675e-54),\n",
       " SpearmanrResult(correlation=-0.6461645694394698, pvalue=1.2431906986455948e-42),\n",
       " KendalltauResult(correlation=-0.5130121830877685, pvalue=2.7679842373359427e-46),\n",
       " KendalltauResult(correlation=-0.45634798541869387, pvalue=5.480159384148773e-37))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('5.zip', 'WordSim-353-standartized.csv', 'cosine')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7085277934443607, pvalue=1.7677073163502675e-54),\n",
       " SpearmanrResult(correlation=-0.6461645694394698, pvalue=1.2431906986455948e-42),\n",
       " KendalltauResult(correlation=-0.5130121830877685, pvalue=2.7679842373359427e-46),\n",
       " KendalltauResult(correlation=-0.45634798541869387, pvalue=5.480159384148773e-37))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. lemmatize MEN euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273992\n",
      "2995\n",
      "200 [[ 0.043955 -0.042658  0.096431 ... -0.036177  0.005109  0.081497]\n",
      " [-0.04143   0.044345  0.036994 ... -0.014002 -0.048183  0.024704]\n",
      " [ 0.064861 -0.031078  0.021033 ... -0.011793  0.049018 -0.036995]\n",
      " ...\n",
      " [ 0.014758 -0.101612  0.017391 ... -0.073066  0.097357 -0.034404]\n",
      " [ 0.013813  0.05582   0.082128 ...  0.044952  0.020532  0.083864]\n",
      " [ 0.049241  0.004803  0.044597 ...  0.043673 -0.02894   0.010062]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0203\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0164\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0159\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0125\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0109\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0152\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0086\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0122\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0121\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0091\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0084\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0070\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0074\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0096\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0065\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0078\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0071\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0044\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0065\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0052\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0044\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0068\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0054\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0037\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0036\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0057\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0056\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0045\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0047\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0036\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0030\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0027\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0043\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0033\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0027\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0032\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0039\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0029\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0035\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0045\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0026\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0010\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0031\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0043\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0034\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0030\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0030\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0031\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0017\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0034\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0025\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0018\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0022\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0020\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0033\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0025\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0025\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0031\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0014\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.760625728585474, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.9207950550718719, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5554079065856331, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.7578220602855057, pvalue=0.0))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('5.zip', 'MEN-standartized.csv', 'euclidean')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.760625728585474, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.9207950550718719, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5554079065856331, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.7578220602855057, pvalue=0.0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. lemmatize MEN cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273992\n",
      "2995\n",
      "200 [[ 0.043955 -0.042658  0.096431 ... -0.036177  0.005109  0.081497]\n",
      " [-0.04143   0.044345  0.036994 ... -0.014002 -0.048183  0.024704]\n",
      " [ 0.064861 -0.031078  0.021033 ... -0.011793  0.049018 -0.036995]\n",
      " ...\n",
      " [ 0.014758 -0.101612  0.017391 ... -0.073066  0.097357 -0.034404]\n",
      " [ 0.013813  0.05582   0.082128 ...  0.044952  0.020532  0.083864]\n",
      " [ 0.049241  0.004803  0.044597 ...  0.043673 -0.02894   0.010062]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7606257987339587, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.7300099849425212, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5554083579388052, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5260564098110365, pvalue=0.0))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('5.zip', 'MEN-standartized.csv', 'cosine')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7606257987339587, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.7300099849425212, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5554083579388052, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5260564098110365, pvalue=0.0))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. lemmatize simlex euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273992\n",
      "996\n",
      "200 [[ 0.081944  0.070888  0.012175 ... -0.027376 -0.043142 -0.04819 ]\n",
      " [ 0.043955 -0.042658  0.096431 ... -0.036177  0.005109  0.081497]\n",
      " [ 0.031562 -0.068909 -0.016195 ...  0.054254  0.057617  0.044717]\n",
      " ...\n",
      " [ 0.064343  0.041916 -0.069158 ...  0.059846 -0.029133  0.082279]\n",
      " [ 0.028022  0.005436  0.070518 ...  0.148056 -0.011683  0.057725]\n",
      " [-0.058465 -0.02852   0.065594 ...  0.016635  0.000731  0.02499 ]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0205\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0156\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0114\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0078\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0052\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0048\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0040\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0029\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0034\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0025\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0016\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0023\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1181e-04\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.9802e-04\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0074e-04\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3275e-04\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9664e-04\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5733e-04\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0011\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0010\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.3645e-04\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1962e-04\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.9993e-04\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6108e-04\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7268e-04\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2294e-04\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9845e-04\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.7995e-04\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3310e-05\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.5105e-04\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.1287e-04\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9381e-04\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3825e-04\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7834e-04\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.7499e-04\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0242e-04\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.0823e-05\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0034e-04\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.7249e-05\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9185e-04\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8595e-04\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3197e-04\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9953e-04\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9103e-04\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1874e-04\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1804e-04\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5841e-04\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2193e-05\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2502e-04\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.41030069393086, pvalue=9.982710446211431e-42),\n",
       " SpearmanrResult(correlation=-0.6088200032688278, pvalue=4.605823534215415e-102),\n",
       " KendalltauResult(correlation=-0.2868649444143602, pvalue=1.0235961422640682e-41),\n",
       " KendalltauResult(correlation=-0.4332655427732197, pvalue=7.876411855231044e-93))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('5.zip', 'SimLex-999-standartized.csv', 'euclidean')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.41030069393086, pvalue=9.982710446211431e-42),\n",
       " SpearmanrResult(correlation=-0.6088200032688278, pvalue=4.605823534215415e-102),\n",
       " KendalltauResult(correlation=-0.2868649444143602, pvalue=1.0235961422640682e-41),\n",
       " KendalltauResult(correlation=-0.4332655427732197, pvalue=7.876411855231044e-93))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. lemmatize simlex cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273992\n",
      "996\n",
      "200 [[ 0.081944  0.070888  0.012175 ... -0.027376 -0.043142 -0.04819 ]\n",
      " [ 0.043955 -0.042658  0.096431 ... -0.036177  0.005109  0.081497]\n",
      " [ 0.031562 -0.068909 -0.016195 ...  0.054254  0.057617  0.044717]\n",
      " ...\n",
      " [ 0.064343  0.041916 -0.069158 ...  0.059846 -0.029133  0.082279]\n",
      " [ 0.028022  0.005436  0.070518 ...  0.148056 -0.011683  0.057725]\n",
      " [-0.058465 -0.02852   0.065594 ...  0.016635  0.000731  0.02499 ]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.410309572203932, pvalue=9.93912834716579e-42),\n",
       " SpearmanrResult(correlation=-0.39960135466712693, pvalue=1.7698736971824294e-39),\n",
       " KendalltauResult(correlation=-0.2868689881829592, pvalue=1.0209434354198436e-41),\n",
       " KendalltauResult(correlation=-0.2774631824216426, pvalue=3.870934663169294e-39))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('5.zip', 'SimLex-999-standartized.csv', 'cosine')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.410309572203932, pvalue=9.93912834716579e-42),\n",
       " SpearmanrResult(correlation=-0.39960135466712693, pvalue=1.7698736971824294e-39),\n",
       " KendalltauResult(correlation=-0.2868689881829592, pvalue=1.0209434354198436e-41),\n",
       " KendalltauResult(correlation=-0.2774631824216426, pvalue=3.870934663169294e-39))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. NON lemmatize wordsim euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302866\n",
      "350\n",
      "200 [[ 0.000587 -0.084463 -0.01506  ...  0.000696  0.019693  0.043772]\n",
      " [ 0.033611  0.023678  0.025785 ...  0.031816  0.091718  0.044066]\n",
      " [ 0.062105  0.0978   -0.069382 ...  0.034753  0.087597 -0.003909]\n",
      " ...\n",
      " [ 0.041623 -0.001717 -0.007894 ... -0.000554  0.067371 -0.008428]\n",
      " [ 0.14492  -0.013378  0.096322 ... -0.072303  0.088542  0.056065]\n",
      " [-0.025886  0.072847 -0.041639 ...  0.040265 -0.06546   0.064321]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0084\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0034\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3701e-04\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0039\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0016\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.6552e-04\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.1266e-04\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.0804e-04\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.2662e-04\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.1825e-05\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.0427e-04\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0015\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 7.4125e-04\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.9577e-04\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8574e-04\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.9995e-05\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.0693e-04\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0000e+0 - 0s 8ms/step - loss: 9.4289e-05\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.2170e-05\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.1945e-04\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 4.2238e-04\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 5.8792e-04\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0012\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 6.6108e-05\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.6956e-04\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.0981e-04\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6.1811e-04\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.5074e-04\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.0571e-04\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2098e-04\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.3724e-04\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.8080e-04\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.1118e-05\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7.6130e-05\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 8.1385e-04\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.6576e-06\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 4.8808e-05\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.9993e-04\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.8192e-05\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.8639e-04\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3.7520e-05\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.6095e-05\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.0546e-04\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 3.1414e-04\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1750e-04\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.2859e-04\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4.9520e-04\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 5.9158e-05\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7149844011090453, pvalue=4.828088525235992e-56),\n",
       " SpearmanrResult(correlation=-0.76228687922488, pvalue=9.963420483917114e-68),\n",
       " KendalltauResult(correlation=-0.5201605756056357, pvalue=1.1475990675828784e-47),\n",
       " KendalltauResult(correlation=-0.5642027943767713, pvalue=9.1635421972056e-56))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('6.zip', 'WordSim-353-standartized.csv', 'euclidean')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7149844011090453, pvalue=4.828088525235992e-56),\n",
       " SpearmanrResult(correlation=-0.76228687922488, pvalue=9.963420483917114e-68),\n",
       " KendalltauResult(correlation=-0.5201605756056357, pvalue=1.1475990675828784e-47),\n",
       " KendalltauResult(correlation=-0.5642027943767713, pvalue=9.1635421972056e-56))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. NON lemmatize wordsim cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302866\n",
      "350\n",
      "200 [[ 0.000587 -0.084463 -0.01506  ...  0.000696  0.019693  0.043772]\n",
      " [ 0.033611  0.023678  0.025785 ...  0.031816  0.091718  0.044066]\n",
      " [ 0.062105  0.0978   -0.069382 ...  0.034753  0.087597 -0.003909]\n",
      " ...\n",
      " [ 0.041623 -0.001717 -0.007894 ... -0.000554  0.067371 -0.008428]\n",
      " [ 0.14492  -0.013378  0.096322 ... -0.072303  0.088542  0.056065]\n",
      " [-0.025886  0.072847 -0.041639 ...  0.040265 -0.06546   0.064321]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0146\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7149844011090453, pvalue=4.828088525235992e-56),\n",
       " SpearmanrResult(correlation=-0.6417422290411958, pvalue=5.1859191910230406e-42),\n",
       " KendalltauResult(correlation=-0.5201605756056357, pvalue=1.1475990675828784e-47),\n",
       " KendalltauResult(correlation=-0.45024396323031074, pvalue=3.768619169459944e-36))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('6.zip', 'WordSim-353-standartized.csv', 'cosine')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7149844011090453, pvalue=4.828088525235992e-56),\n",
       " SpearmanrResult(correlation=-0.6417422290411958, pvalue=5.1859191910230406e-42),\n",
       " KendalltauResult(correlation=-0.5201605756056357, pvalue=1.1475990675828784e-47),\n",
       " KendalltauResult(correlation=-0.45024396323031074, pvalue=3.768619169459944e-36))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. NON lemmatize MEN euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302866\n",
      "2990\n",
      "200 [[ 0.186102 -0.01899   0.043054 ...  0.011151  0.066     0.015289]\n",
      " [ 0.077927  0.00074   0.035034 ...  0.041995 -0.001263 -0.019273]\n",
      " [ 0.100433 -0.048706  0.009059 ... -0.066203  0.045879 -0.01523 ]\n",
      " ...\n",
      " [ 0.169143 -0.029529  0.095029 ... -0.075348  0.14589  -0.045791]\n",
      " [ 0.070053  0.033203  0.066227 ...  0.023616 -0.073134 -0.032462]\n",
      " [ 0.152246 -0.070508 -0.035468 ...  0.023608  0.031194 -0.013409]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0227\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0233\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0180\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0145\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0157\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0144\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0100\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0119\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0092\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0079\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0074\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0092\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0091\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0055\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0053\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0065\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0054\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0075\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0063\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0058\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0049\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0059\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0038\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0056\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0047\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0042\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0037\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0053\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0043\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0043\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0041\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0042\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0041\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0033\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0035\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0042\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0038\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0037\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0035\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0021\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0028\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0039\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0026\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0020\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0019\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0034\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0029\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0038\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0024\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0023\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0027\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0020\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0024\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0025\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0020\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0025\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0029\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0029\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0035\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0034\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0016\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0012\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0022\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0016\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0019\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0023\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0026\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0015\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0021\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0024\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0018\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0027\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0015\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0014\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0023\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0015\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0020\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0018\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0024\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.740759892454674, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.9189012016876532, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5344762699724819, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.7563675319674827, pvalue=0.0))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('6.zip', 'MEN-standartized.csv', 'euclidean')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.740759892454674, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.9189012016876532, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5344762699724819, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.7563675319674827, pvalue=0.0))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. NON lemmatize MEN cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302866\n",
      "2990\n",
      "200 [[ 0.186102 -0.01899   0.043054 ...  0.011151  0.066     0.015289]\n",
      " [ 0.077927  0.00074   0.035034 ...  0.041995 -0.001263 -0.019273]\n",
      " [ 0.100433 -0.048706  0.009059 ... -0.066203  0.045879 -0.01523 ]\n",
      " ...\n",
      " [ 0.169143 -0.029529  0.095029 ... -0.075348  0.14589  -0.045791]\n",
      " [ 0.070053  0.033203  0.066227 ...  0.023616 -0.073134 -0.032462]\n",
      " [ 0.152246 -0.070508 -0.035468 ...  0.023608  0.031194 -0.013409]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7407603538008262, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.7102571241219192, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5344766032338761, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.506733352037184, pvalue=0.0))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('6.zip', 'MEN-standartized.csv', 'cosine')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.7407603538008262, pvalue=0.0),\n",
       " SpearmanrResult(correlation=-0.7102571241219192, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.5344766032338761, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.506733352037184, pvalue=0.0))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. NON lemmatize simlex euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302866\n",
      "994\n",
      "200 [[ 0.071775  0.019376  0.092361 ...  0.007572  0.144104 -0.051339]\n",
      " [ 0.186102 -0.01899   0.043054 ...  0.011151  0.066     0.015289]\n",
      " [ 0.032881 -0.033576  0.039352 ... -0.023929  0.057046  0.126246]\n",
      " ...\n",
      " [ 0.136787  0.020429 -0.111552 ... -0.028137  0.0664   -0.054412]\n",
      " [ 0.006196 -0.03032   0.088371 ...  0.151074 -0.009712  0.067667]\n",
      " [-0.037721  0.054703  0.135236 ...  0.015538  0.046769  0.046268]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0257\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0156\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0137\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0089\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0058\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0046\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0033\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.1290e-04\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 9.0929e-04\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0012\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.1659e-04\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.0255e-04\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.8033e-04\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.1426e-04\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.1882e-04\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8257e-04\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.6264e-04\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5770e-04\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.2204e-04\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2291e-04\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.9449e-04\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2660e-04\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6769e-04\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.4963e-04\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.4585e-04\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7592e-04\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.8945e-04\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5644e-04\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6048e-04\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.5348e-04\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5682e-04\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.9537e-04\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.4853e-04\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2032e-05\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2796e-04\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.4829e-04\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3003e-04\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1847e-04\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.1902e-04\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.6415e-04\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0950e-05\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.4994e-05\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7419e-04\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5633e-04\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.2238e-04\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.7424e-04\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.1933e-04\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5821e-04\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2260e-04\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2917e-04\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6667e-05\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.3697e-05\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8091e-04\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4990e-04\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.5048e-05\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.6411e-05\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.8739e-05\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.3053e-05\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.6262e-04\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.3365e-04\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8680e-04\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.5253e-04\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1288e-04\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8595e-04\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.8661e-04\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.8089e-05\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.0470e-05\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.6849e-04\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.5327e-05\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.9665e-04\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.7955e-05\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.39672429489470695, pvalue=8.194700471508046e-39),\n",
       " SpearmanrResult(correlation=-0.6191010230400267, pvalue=3.1092436402981607e-106),\n",
       " KendalltauResult(correlation=-0.27664369440557113, pvalue=7.649997002013556e-39),\n",
       " KendalltauResult(correlation=-0.4424614177329303, pvalue=1.542306862157365e-96))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('6.zip', 'SimLex-999-standartized.csv', 'euclidean')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.39672429489470695, pvalue=8.194700471508046e-39),\n",
       " SpearmanrResult(correlation=-0.6191010230400267, pvalue=3.1092436402981607e-106),\n",
       " KendalltauResult(correlation=-0.27664369440557113, pvalue=7.649997002013556e-39),\n",
       " KendalltauResult(correlation=-0.4424614177329303, pvalue=1.542306862157365e-96))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. NON lemmatize simlex cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302866\n",
      "994\n",
      "200 [[ 0.071775  0.019376  0.092361 ...  0.007572  0.144104 -0.051339]\n",
      " [ 0.186102 -0.01899   0.043054 ...  0.011151  0.066     0.015289]\n",
      " [ 0.032881 -0.033576  0.039352 ... -0.023929  0.057046  0.126246]\n",
      " ...\n",
      " [ 0.136787  0.020429 -0.111552 ... -0.028137  0.0664   -0.054412]\n",
      " [ 0.006196 -0.03032   0.088371 ...  0.151074 -0.009712  0.067667]\n",
      " [-0.037721  0.054703  0.135236 ...  0.015538  0.046769  0.046268]]\n",
      "Training neural network\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0000e+00\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.39672429489470695, pvalue=8.194700471508046e-39),\n",
       " SpearmanrResult(correlation=-0.38096873447343776, pvalue=1.0984456903073025e-35),\n",
       " KendalltauResult(correlation=-0.27664369440557113, pvalue=7.649997002013556e-39),\n",
       " KendalltauResult(correlation=-0.2639437644683027, pvalue=1.637063841100438e-35))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = do_experiment('6.zip', 'SimLex-999-standartized.csv', 'cosine')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SpearmanrResult(correlation=-0.39672429489470695, pvalue=8.194700471508046e-39),\n",
       " SpearmanrResult(correlation=-0.38096873447343776, pvalue=1.0984456903073025e-35),\n",
       " KendalltauResult(correlation=-0.27664369440557113, pvalue=7.649997002013556e-39),\n",
       " KendalltauResult(correlation=-0.2639437644683027, pvalue=1.637063841100438e-35))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v101",
   "language": "python",
   "name": "v101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
